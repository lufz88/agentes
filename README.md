# ğŸ§  Zero to Hero: Arquitecturas AgÃ©nticas

> **Stack**: TypeScript + Node.js (Backend/CLI) Â· React (Frontend) Â· Java/Spring AI (Enterprise)
> **Sin Python** â€” Todo en tu stack nativo.

---

## Tabla de contenidos

- [Requisitos previos](#requisitos-previos)
- [ConfiguraciÃ³n del entorno](#configuraciÃ³n-del-entorno)
- [Proveedores LLM soportados](#proveedores-llm-soportados)
- [Proyecto 01 â€” CLI Agent](#proyecto-01--cli-agent)
- [Proyecto 02 â€” Generative UI](#proyecto-02--generative-ui)
- [Proyecto 03 â€” Java RAG Agent](#proyecto-03--java-rag-agent)
- [Roadmap tÃ©cnico](#roadmap-tÃ©cnico)
- [AnatomÃ­a de un agente](#anatomÃ­a-de-un-agente)
- [Estructura del workspace](#estructura-del-workspace)
- [Troubleshooting](#troubleshooting)

---

## Requisitos previos

| Herramienta | VersiÃ³n mÃ­nima | Para quÃ© proyecto | InstalaciÃ³n |
|---|---|---|---|
| **Node.js** | 20+ | 01, 02 | [nodejs.org](https://nodejs.org/) |
| **npm** | 9+ | 01, 02 | Viene con Node.js |
| **Java JDK** | 21 | 03 | `sudo apt install openjdk-21-jdk` Ã³ [SDKMAN](https://sdkman.io/) |
| **Maven** | 3.9+ | 03 | `sudo apt install maven` Ã³ viene con SDKMAN |
| **Ollama** (opcional) | latest | 01, 02, 03 | `curl -fsSL https://ollama.com/install.sh \| sh` |

> **Ollama** es necesario si usÃ¡s un proveedor cloud que no soporta embeddings (Groq, Gemini, GitHub Models) en el proyecto 03, o si querÃ©s un LLM 100% local.

---

## ConfiguraciÃ³n del entorno

### 1. Archivo `.env` (compartido)

Los tres proyectos leen de un **Ãºnico archivo `.env` en la raÃ­z del workspace**:

```bash
# agentes/.env
PROVIDER=github          # ollama | groq | gemini | openai | github
OPENAI_API_KEY=tu-key    # API key del proveedor elegido
```

Opcional â€” para override manual (generalmente no hace falta):

```bash
# MODEL=gpt-4o-mini                  # Fuerza un modelo especÃ­fico
# OPENAI_BASE_URL=https://...        # Fuerza una URL base
```

> Los proyectos TypeScript usan `--env-file=../.env` de Node.js.
> El proyecto Java usa `EnvLoader.java` que busca `../.env` automÃ¡ticamente.

### 2. Crear el archivo

```bash
cd agentes/
cp .env.example .env   # si existe, o crear manualmente:
cat > .env << 'EOF'
PROVIDER=ollama
OPENAI_API_KEY=ollama
EOF
```

### 3. Instalar Ollama (opciÃ³n local, sin API key)

```bash
# Instalar Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Descargar modelos
ollama pull llama3.1           # Chat (~4.7 GB)
ollama pull nomic-embed-text   # Embeddings (~274 MB) â€” necesario para proyecto 03
```

---

## Proveedores LLM soportados

Los tres proyectos comparten la misma configuraciÃ³n de proveedores. Todos son OpenAI-compatible:

| Provider | `PROVIDER=` | `OPENAI_API_KEY=` | Modelo de chat | Costo | Obtener key |
|---|---|---|---|---|---|
| **Ollama** | `ollama` | (no necesita) | `llama3.1` | Gratis (local) | â€” |
| **Groq** | `groq` | `gsk_...` | `llama-3.1-70b-versatile` | Gratis (free tier) | [console.groq.com](https://console.groq.com) |
| **Gemini** | `gemini` | `AI...` | `gemini-2.0-flash` | Gratis (free tier) | [aistudio.google.com/apikey](https://aistudio.google.com/apikey) |
| **OpenAI** | `openai` | `sk-...` | `gpt-4o-mini` | Pago | [platform.openai.com](https://platform.openai.com) |
| **GitHub Models** | `github` | `ghp_...` | `gpt-4o-mini` | Gratis (con GitHub) | [github.com/marketplace/models](https://github.com/marketplace/models) |

### Embeddings por proveedor (proyecto 03)

El proyecto Java usa embeddings para RAG. No todos los proveedores ofrecen un endpoint de embeddings:

| Provider | Embeddings | Modelo embeddings | Requiere Ollama local |
|---|---|---|---|
| Ollama | Propio | `nomic-embed-text` | No (ya ES Ollama) |
| Groq | **No soporta** | `nomic-embed-text` via Ollama | SÃ­ |
| Gemini | **No soporta** | `nomic-embed-text` via Ollama | SÃ­ |
| OpenAI | Propio | `text-embedding-3-small` | No |
| GitHub Models | **No soporta** | `nomic-embed-text` via Ollama | SÃ­ |

> Si usÃ¡s Groq, Gemini o GitHub Models para el proyecto 03, necesitÃ¡s tener Ollama corriendo localmente para los embeddings: `ollama pull nomic-embed-text`

---

## Proyecto 01 â€” CLI Agent

Agente conversacional en terminal con tool calling y reasoning loop.

### Conceptos que enseÃ±a

- LLM como funciÃ³n (chat completions API)
- Tool calling con JSON Schema
- Reasoning loop: think â†’ act â†’ observe â†’ repeat
- ValidaciÃ³n con Zod

### Setup y ejecuciÃ³n

```bash
cd 01-cli-agent
npm install
```

**OpciÃ³n A â€” Con Ollama (local, sin key):**
```bash
# Asegurate de tener ollama corriendo: ollama serve
npm run dev
```

**OpciÃ³n B â€” Con proveedor cloud:**
```bash
# Ya con .env configurado en la raÃ­z:
npm run dev

# O inline:
PROVIDER=github OPENAI_API_KEY=ghp_xxx npm run dev
```

### Uso

Se abre un REPL interactivo. ProbÃ¡:

```
tÃº> Â¿QuÃ© clima hace en Buenos Aires?
tÃº> CalculÃ¡ 145 * 87 + 33
tÃº> ListÃ¡ los archivos en el directorio actual
tÃº> Salir
```

### Tools disponibles

| Tool | QuÃ© hace |
|---|---|
| `get_weather` | Simula consulta de clima |
| `calculate` | EvalÃºa expresiones matemÃ¡ticas |
| `read_file` / `list_directory` | Lee archivos y directorios locales |

### Scripts

| Comando | DescripciÃ³n |
|---|---|
| `npm run dev` | Ejecuta con tsx (hot reload, lee `.env`) |
| `npm run build` | Compila a JavaScript |
| `npm start` | Ejecuta versiÃ³n compilada |

---

## Proyecto 02 â€” Generative UI

Agente que genera componentes React dinÃ¡micamente, con streaming via SSE.

### Conceptos que enseÃ±a

- Server-Sent Events (SSE) para streaming
- Generative UI â€” el LLM decide quÃ© componentes mostrar
- State management agÃ©ntico con Zustand
- Tool calling visual (tools que retornan componentes)

### Setup y ejecuciÃ³n

```bash
# Terminal 1 â€” Backend (Express + SSE)
cd 02-generative-ui/backend
npm install
npm run dev    # â†’ http://localhost:3001

# Terminal 2 â€” Frontend (React + Vite)
cd 02-generative-ui/frontend
npm install
npm run dev    # â†’ http://localhost:5173
```

AbrÃ­ **http://localhost:5173** en el navegador.

> El frontend tiene un proxy configurado en `vite.config.ts` que redirige `/api/*` al backend en `:3001`, asÃ­ que sÃ³lo necesitÃ¡s abrir `:5173`.

### Uso

EscribÃ­ mensajes que generen componentes visuales:

```
tÃº> Mostrame el clima en Madrid
tÃº> HacÃ© un grÃ¡fico de barras con las ventas por mes: Ene 100, Feb 150, Mar 200
tÃº> ArmÃ¡ una tabla con los paÃ­ses mÃ¡s poblados de SudamÃ©rica
```

### Tools visuales

| Tool | Componente React | Ejemplo |
|---|---|---|
| `show_weather_card` | `<WeatherCard>` | Tarjeta de clima |
| `show_chart` | `<Chart>` | GrÃ¡ficos (barras, lÃ­neas, pie, Ã¡rea) |
| `show_data_table` | `<DataTable>` | Tablas de datos interactivas |

### Scripts

| Comando | UbicaciÃ³n | DescripciÃ³n |
|---|---|---|
| `npm run dev` | `backend/` | Inicia servidor Express con hot reload |
| `npm run dev` | `frontend/` | Inicia Vite dev server |
| `npm run build` | `frontend/` | Build de producciÃ³n |

---

## Proyecto 03 â€” Java RAG Agent

Agente empresarial con RAG (Retrieval Augmented Generation), multi-agent orchestration, y frontend web integrado.

### Conceptos que enseÃ±a

- Pipeline RAG: ingest â†’ chunk â†’ embed â†’ retrieve â†’ augment â†’ generate
- Spring AI con OpenAI-compatible backends
- Multi-agent orchestration
- Tool calling en Java
- Embeddings y vector store

### Requisitos especÃ­ficos

- Java 21+
- Maven 3.9+
- Ollama corriendo si usÃ¡s un provider cloud (para embeddings)

### Setup y ejecuciÃ³n

```bash
cd 03-java-rag-agent

# Compilar
mvn package -DskipTests

# Ejecutar (lee .env del directorio padre automÃ¡ticamente)
mvn spring-boot:run
```

AbrÃ­ **http://localhost:8080** en el navegador (el frontend estÃ¡ embebido en el JAR).

### ConfiguraciÃ³n multi-provider

El proyecto lee automÃ¡ticamente `PROVIDER` y `OPENAI_API_KEY` de `../.env`. La resoluciÃ³n funciona asÃ­:

```
main() â†’ EnvLoader.load()       â†’ lee ../.env como System properties
       â†’ ProviderResolver.resolve() â†’ mapea PROVIDER a URLs/modelos concretos
       â†’ SpringApplication.run()    â†’ Spring AI usa las properties resueltas
```

Para cambiar de proveedor, solo editÃ¡ `../.env` y reiniciÃ¡:

```bash
# .env
PROVIDER=github
OPENAI_API_KEY=ghp_xxxxx
```

Si usÃ¡s Groq, Gemini o GitHub Models, asegurate de tener Ollama corriendo:

```bash
ollama serve                    # Si no estÃ¡ ya corriendo
ollama pull nomic-embed-text    # Solo la primera vez
```

### Endpoints de la API

| MÃ©todo | Endpoint | DescripciÃ³n |
|---|---|---|
| `GET` | `/` | Frontend web (HTML embebido) |
| `GET` | `/api/info` | Info del proveedor activo (modelo, URL, etc.) |
| `POST` | `/api/chat` | Chat con RAG `{"message": "..."}` |
| `POST` | `/api/orchestrate` | Chat multi-agente `{"message": "..."}` |
| `POST` | `/api/documents/upload` | Subir documento (multipart/form-data) |
| `POST` | `/api/documents/ingest-all` | Ingestar todos los docs de `./documents/` |
| `POST` | `/api/reset` | Limpiar historial de conversaciÃ³n |

### Testing con curl

```bash
# Info del proveedor
curl http://localhost:8080/api/info | python3 -m json.tool

# Chat simple
curl -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Â¿QuÃ© es un agente de IA?"}' | python3 -m json.tool

# Subir un documento para RAG
curl -X POST http://localhost:8080/api/documents/upload \
  -F "file=@mi-documento.pdf"

# Ingestar todos los docs del directorio ./documents/
curl -X POST http://localhost:8080/api/documents/ingest-all

# Chat multi-agente
curl -X POST http://localhost:8080/api/orchestrate \
  -H "Content-Type: application/json" \
  -d '{"message": "AnalizÃ¡ los documentos y dame un resumen"}' | python3 -m json.tool

# Reset conversaciÃ³n
curl -X POST http://localhost:8080/api/reset
```

### Uso del frontend web

1. AbrÃ­ http://localhost:8080
2. El badge superior muestra el proveedor activo y modelo
3. EscribÃ­ un mensaje para chatear (modo RAG por defecto)
4. UsÃ¡ el toggle para cambiar entre modo **RAG** y **Multi-Agent**
5. SubÃ­ documentos con el botÃ³n de upload (PDF, TXT, MD, DOCX)
6. TambiÃ©n podÃ©s ingestar todo el directorio `./documents/` de una vez

### Agregar documentos para RAG

PodÃ©s agregar documentos de dos formas:

**OpciÃ³n A â€” Via frontend:**
HacÃ© click en el Ã­cono de upload y seleccionÃ¡ un archivo.

**OpciÃ³n B â€” Via directorio:**
```bash
# Copiar archivos al directorio de documentos
cp mi-archivo.pdf 03-java-rag-agent/documents/

# Ingestar todos los documentos del directorio
curl -X POST http://localhost:8080/api/documents/ingest-all
```

Formatos soportados: PDF, TXT, Markdown, DOCX, HTML (via Apache Tika).

---

## Roadmap tÃ©cnico

### Fase 1 â€” Fundamentos (Semana 1-2)
| Concepto | QuÃ© aprenderÃ¡s | Proyecto |
|---|---|---|
| LLM como funciÃ³n | Llamar a un LLM, parsear respuestas estructuradas | `01-cli-agent` |
| Tool Calling | Definir schemas JSON, ejecutar funciones locales | `01-cli-agent` |
| Reasoning Loop | Ciclo `think â†’ act â†’ observe â†’ repeat` | `01-cli-agent` |
| Prompt Engineering para agentes | System prompts, few-shot, chain-of-thought | `01-cli-agent` |

### Fase 2 â€” Agentes con UI (Semana 3-4)
| Concepto | QuÃ© aprenderÃ¡s | Proyecto |
|---|---|---|
| Streaming de respuestas | Server-Sent Events + React state | `02-generative-ui` |
| Generative UI | El agente decide quÃ© componentes renderizar | `02-generative-ui` |
| State Management agÃ©ntico | Zustand/useReducer controlado por el agente | `02-generative-ui` |
| Tool Calling visual | Tools que retornan componentes React | `02-generative-ui` |

### Fase 3 â€” Enterprise & RAG (Semana 5-6)
| Concepto | QuÃ© aprenderÃ¡s | Proyecto |
|---|---|---|
| RAG Pipeline | Embeddings, vector store, retrieval | `03-java-rag-agent` |
| Spring AI | Framework de agentes en Java | `03-java-rag-agent` |
| Multi-Agent Orchestration | Agentes especializados que colaboran | `03-java-rag-agent` |
| Memory & State persistente | Conversaciones con contexto a largo plazo | `03-java-rag-agent` |

---

## AnatomÃ­a de un agente

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AGENTE                     â”‚
â”‚                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  PLAN   â”‚â”€â”€â”€â–¶â”‚   ACT    â”‚â”€â”€â”€â–¶â”‚OBSERVEâ”‚  â”‚
â”‚   â”‚ (Think) â”‚    â”‚(Tool Call)â”‚    â”‚(Parse) â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â–²â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â”‚
â”‚        â”‚                             â”‚       â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚              Reasoning Loop                  â”‚
â”‚                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚            STATE / MEMORY            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚  Tool 1  â”‚ â”‚  Tool 2  â”‚ â”‚  Tool N  â”‚    â”‚
â”‚   â”‚(API Call)â”‚ â”‚(DB Query)â”‚ â”‚(File I/O)â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Estructura del workspace

```
agentes/
â”œâ”€â”€ .env                         â† Variables compartidas (PROVIDER, OPENAI_API_KEY)
â”œâ”€â”€ README.md                    â† EstÃ¡s aquÃ­
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ summary.md               â† Explicaciones detalladas de conceptos
â”‚   â”œâ”€â”€ tool-calling-reference.md
â”‚   â””â”€â”€ copilot-workflow.md
â”œâ”€â”€ 01-cli-agent/                â† Proyecto 1: CLI Agent (TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ index.ts             â† Entry point + selecciÃ³n de provider
â”‚   â”‚   â”œâ”€â”€ agent.ts             â† Reasoning loop principal
â”‚   â”‚   â”œâ”€â”€ llm.ts               â† Cliente LLM (OpenAI compatible)
â”‚   â”‚   â”œâ”€â”€ tools/               â† Definiciones de tools (weather, calc, fs)
â”‚   â”‚   â””â”€â”€ types.ts             â† Interfaces y schemas Zod
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”œâ”€â”€ 02-generative-ui/            â† Proyecto 2: Generative UI (React + Express)
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ server.ts        â† Express + SSE endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ agent.ts         â† Agente streaming con UI actions
â”‚   â”‚   â”‚   â””â”€â”€ tools/           â† Tools que generan componentes
â”‚   â”‚   â””â”€â”€ package.json
â”‚   â””â”€â”€ frontend/
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ App.tsx           â† Layout principal
â”‚       â”‚   â”œâ”€â”€ components/       â† WeatherCard, Chart, DataTable, DynamicComponent
â”‚       â”‚   â”œâ”€â”€ hooks/            â† useAgentSSE (consumir SSE)
â”‚       â”‚   â””â”€â”€ store/            â† Zustand store (agent-store.ts)
â”‚       â”œâ”€â”€ vite.config.ts        â† Proxy /api â†’ :3001
â”‚       â””â”€â”€ package.json
â””â”€â”€ 03-java-rag-agent/           â† Proyecto 3: Java RAG (Spring Boot + Spring AI)
    â”œâ”€â”€ src/main/
    â”‚   â”œâ”€â”€ java/com/agentes/rag/
    â”‚   â”‚   â”œâ”€â”€ RagAgentApplication.java  â† Main (carga .env + resuelve provider)
    â”‚   â”‚   â”œâ”€â”€ agent/
    â”‚   â”‚   â”‚   â”œâ”€â”€ RagAgent.java         â† Agente RAG principal
    â”‚   â”‚   â”‚   â”œâ”€â”€ MultiAgentOrchestrator.java
    â”‚   â”‚   â”‚   â””â”€â”€ AgentController.java  â† REST API
    â”‚   â”‚   â”œâ”€â”€ config/
    â”‚   â”‚   â”‚   â”œâ”€â”€ EnvLoader.java        â† Carga ../.env como System props
    â”‚   â”‚   â”‚   â”œâ”€â”€ ProviderResolver.java â† Mapea PROVIDER â†’ URLs/modelos
    â”‚   â”‚   â”‚   â””â”€â”€ RagConfig.java        â† Beans de embeddings + vector store
    â”‚   â”‚   â”œâ”€â”€ rag/
    â”‚   â”‚   â”‚   â”œâ”€â”€ DocumentIngestionService.java  â† Ingest pipeline
    â”‚   â”‚   â”‚   â””â”€â”€ RetrievalService.java          â† RAG retrieval
    â”‚   â”‚   â””â”€â”€ tools/
    â”‚   â”‚       â”œâ”€â”€ SearchDocumentsTool.java
    â”‚   â”‚       â””â”€â”€ DataAnalysisTool.java
    â”‚   â””â”€â”€ resources/
    â”‚       â”œâ”€â”€ application.yml           â† Config Spring AI
    â”‚       â””â”€â”€ static/index.html         â† Frontend web embebido
    â”œâ”€â”€ documents/                        â† Directorio para documentos RAG
    â””â”€â”€ pom.xml
```

---

## Troubleshooting

### General

| Problema | Causa | SoluciÃ³n |
|---|---|---|
| `âŒ Falta API key` | No hay `OPENAI_API_KEY` configurada | CreÃ¡ `agentes/.env` con `PROVIDER=ollama` o tu key |
| Timeout / conexiÃ³n rechazada | Ollama no estÃ¡ corriendo | `ollama serve` en otra terminal |
| Modelo no encontrado | No descargaste el modelo | `ollama pull llama3.1` |

### Proyecto 02

| Problema | Causa | SoluciÃ³n |
|---|---|---|
| CORS error en el navegador | Frontend no usa el proxy de Vite | AbrÃ­ `localhost:5173`, no `localhost:3001` |
| Componentes no renderizan | Backend no estÃ¡ corriendo | VerificÃ¡ que el backend estÃ© en `:3001` |

### Proyecto 03

| Problema | Causa | SoluciÃ³n |
|---|---|---|
| 404 Resource not found (chat) | GitHub Models usa path sin `/v1` | Ya resuelto en `RagConfig.java` â€” asegurate de tener la versiÃ³n actual |
| 404 en embeddings | Provider no soporta `/v1/embeddings` | Asegurate de que Ollama estÃ© corriendo: `ollama serve` |
| Bean conflict (`embeddingModel`) | Conflicto con `TransformersEmbeddingModel` auto-config | Ya resuelto con `allow-bean-definition-overriding: true` |
| 405 Method Not Allowed (upload) | Accediendo desde URL incorrecta | UsÃ¡ `http://localhost:8080` (no el dev server del frontend) |
| `mvn package` falla | Java 21 no instalado | `java -version` debe decir 21+ |
| Embeddings lentos la primera vez | Ollama descargando modelo | EsperÃ¡ a que termine `ollama pull nomic-embed-text` |

### Verificar que todo funciona

```bash
# 01 â€” CLI Agent
cd 01-cli-agent && npm install && npm run dev
# EscribÃ­ "hola" â†’ deberÃ­as ver respuesta del LLM

# 02 â€” Generative UI (dos terminales)
cd 02-generative-ui/backend && npm install && npm run dev
cd 02-generative-ui/frontend && npm install && npm run dev
# AbrÃ­ http://localhost:5173 â†’ escribÃ­ "clima en Madrid"

# 03 â€” Java RAG
cd 03-java-rag-agent && mvn package -DskipTests && mvn spring-boot:run
# AbrÃ­ http://localhost:8080 â†’ escribÃ­ "hola"
# O con curl:
curl -s http://localhost:8080/api/info | python3 -m json.tool
curl -s -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"hola"}' | python3 -m json.tool
```

---

## DocumentaciÃ³n adicional

- [docs/summary.md](docs/summary.md) â€” Explicaciones detalladas de todos los conceptos (RAG, Agentes, Zod, SSE, Embeddings, etc.)
- [docs/tool-calling-reference.md](docs/tool-calling-reference.md) â€” Referencia de tool calling
- [docs/copilot-workflow.md](docs/copilot-workflow.md) â€” Workflow con Copilot
