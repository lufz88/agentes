# ============================================================
# Configuración del proveedor LLM
# Copia este archivo como .env y descomenta UNA opción
# ============================================================

# ---- OPCIÓN 1: Ollama (local, gratis, sin internet) ----
# Instala: curl -fsSL https://ollama.com/install.sh | sh
# Descarga modelo: ollama pull llama3.1
# PROVIDER=ollama
# No necesita API key ni configuración extra

# ---- OPCIÓN 2: Groq (cloud, gratis, rápido) ----
# Crea cuenta: https://console.groq.com
# PROVIDER=groq
# OPENAI_API_KEY=gsk_tu_key_aqui

# ---- OPCIÓN 3: Google Gemini (cloud, free tier generoso) ----  
# Genera key: https://aistudio.google.com/apikey
# PROVIDER=gemini
# OPENAI_API_KEY=tu_key_de_gemini

# ---- OPCIÓN 4: GitHub Models (gratis con cuenta GitHub) ----
# Genera token: https://github.com/marketplace/models
# PROVIDER=github
# OPENAI_API_KEY=ghp_tu_token

# ---- OPCIÓN 5: OpenAI (pago) ----
# PROVIDER=openai
# OPENAI_API_KEY=sk-tu_key

# ---- Sobreescribir modelo (opcional) ----
# MODEL=llama3.1
